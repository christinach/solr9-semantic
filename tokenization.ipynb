{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83b8c827-fd08-4db7-8d8a-f7548a2fae53",
   "metadata": {},
   "source": [
    "- The Transformers library provides pretrained models and tools for NLP tasks.\n",
    "- Pytorch library: A deep learning framework for building and training neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839bd32-f9cf-4954-b638-d2ff5e1890c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed torch from Pipfile.\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K✔ Success! Locking packages...\n",
      "\u001b[2K\u001b[32m⠴\u001b[0m Locking packages...\n",
      "\u001b[1A\u001b[2K\u001b[1;32mUninstalling torch...\u001b[0m\n",
      "\u001b[36mFound existing installation: torch 2.2.2\u001b[0m\n",
      "\u001b[36mUninstalling torch-2.2.2:\u001b[0m\n",
      "\u001b[36m  Successfully uninstalled torch-2.2.2\u001b[0m\n",
      "\n",
      "\u001b[1;32mInstalling transformers...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[1;32mInstalling torch==2.2.0...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[1;32mInstalling numpy==2.0...\u001b[0m\n",
      "✔ Installation Succeeded\n",
      "\u001b[1mInstalling dependencies from Pipfile.lock \u001b[0m\u001b[1;39m(a07b06)...\u001b[0m\n",
      "\u001b[32mAll dependencies are now up-to-date!\u001b[0m\n",
      "\u001b[1;32mUpgrading\u001b[0m transformers, \u001b[33mtorch\u001b[0m==\u001b[1;36m2.2\u001b[0m.\u001b[1;36m0\u001b[0m, \u001b[33mnumpy\u001b[0m==\u001b[1;36m2.0\u001b[0m in \u001b[39m dependencies.\u001b[0m\n",
      "\u001b[?25lBuilding requirements...\n",
      "\u001b[2KResolving dependencies....\n",
      "\u001b[2K\u001b[32m⠼\u001b[0m Locking packages..."
     ]
    }
   ],
   "source": [
    "!pipenv uninstall torch\n",
    "!pipenv install transformers torch==2.2.0 numpy==2.0\n",
    "\n",
    "# import os \n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a2bacd-4504-4b3b-937b-e803754d95cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show versions: \n",
    "!pipenv run pip freeze | grep tensorflow\n",
    "!pipenv run pip freeze | grep torch\n",
    "!pipenv run pip freeze | grep numpy\n",
    "# Show Python version\n",
    "import os\n",
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cbdaf-7d29-4056-91e2-b75e125b7baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pipenv install pybind11>=2.12\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "# Load BERT tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize with BERT tokenizer\n",
    "bert_inputs = bert_tokenizer(text, return_tensors='pt')\n",
    "\n",
    "print(\"Token IDs:\", bert_inputs['input_ids'])\n",
    "\n",
    "attention_mask = bert_inputs['attention_mask']\n",
    "print(\"Attention Mask:\", attention_mask)\n",
    "\n",
    "token_type_ids = bert_inputs['token_type_ids']\n",
    "print(\"Token Type IDs:\", token_type_ids)\n",
    "\n",
    "# Print the tokens themselves to understand the splits\n",
    "tokens = bert_tokenizer.convert_ids_to_tokens(bert_inputs['input_ids'][0])\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebadcc-8a08-44ec-bc9f-e783833e389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define the text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Obtain the embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden state (embeddings)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "# Print the dimensions of the embeddings\n",
    "print(\"Shape of the last hidden state (embeddings):\", last_hidden_states.shape)\n",
    "\n",
    "# Print embeddings for each token along with their vector dimension\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "for token, embedding in zip(tokens, last_hidden_states[0]):\n",
    "    print(f\"Token: {token}, Embedding Dimension: {embedding.shape}, Embedding (first 5 components): {embedding[:5]}...\")  # Display first 5 components for brevity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
